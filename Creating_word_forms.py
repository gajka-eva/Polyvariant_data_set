# -*- coding: utf-8 -*-
"""Creating_word_forms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qDI5ph0T4Ye5-7Cvm7Wf84uXnLCavUPr
"""

!pip install pymorphy2
import pymorphy2
import pandas as pd

# Открытие файла
data = pd.read_csv('/content/Tikhonov_data.csv')
data.head()

# Создание отдельных фрагментов датасета по выделенным частям речи
df_v = data.query('pos == "V"')
df_a = data.query('pos == "A"')
df_s = data.query('pos == "S"')

# Количество слов для выбора
n = 300

# Проверка, что в датасета достаточно строк
if len(data) < n:
    raise ValueError(f"В DataFrame только {len(df_v)} строк, но необходимо {n}.")

# Случайный отбор 300 слов
df_sample = df_v.sample(n=n, random_state=42)

# Вывод результатов
print(df_sample)

# Сохранение результатов в CSV файл
df_sample.to_csv('tikhonov_v.csv', index=False)

ti_s = pd.read_csv('/content/tikhonov_s.csv')
ti_v = pd.read_csv('/content/tikhonov_v.csv')
ti_a = pd.read_csv('/content/tikhonov_a.csv')

# Объединение фрагментов
ti_pos = pd.concat([ti_s, ti_v, ti_a], ignore_index=True)

# Создание объекта анализатора
morph = pymorphy2.MorphAnalyzer()

# Список для хранения данных для каждого слова
data = []

# Проход по каждому слову из списка
for word in ti_pos['lemma']:
    # Анализ слова
    parsed_word = morph.parse(word)[0]

    # Получение всех форм слова
    all_forms = parsed_word.lexeme

    # Добавление форм слова в список
    for form in all_forms:
        data.append({'lemma': word, 'form_lemma': form.word})

# Создание датасета из списка данных
df = pd.DataFrame(data)

# Удаление дубликатов
df = df.drop_duplicates()

# Переиндексация после удаления
df.reset_index(drop=True, inplace=True)

# Сохранение датафрейма в файл
df.to_csv('forms_dataset_tikhonov.csv', index=False)

# Выполнение слияния по столбцу 'lemma'. Слияние с основным датасетом проводится, для того чтобы разметить формы слова
df_merged = pd.merge(df, data, on='lemma', how='left')

# Вывод результата
print(df_merged)

# Сохранение результатов в CSV файл
df_merged.to_csv('merged_data.csv', index=False)

# Функция для обработки каждой строки в столбце
def process_morphemic_structure(row):
    # Разделение строки по символу
    base_word = row.rsplit('/', 1)[0]
    # Удаление всех элементов морфемной структуры и символов / и :
    cleaned_word = base_word.replace('ROOT', '').replace('SUFF', '').replace('PREF', '').replace('LINK', '').replace('/', '').replace(':', '')
    return cleaned_word

# Применение функции к столбцу "morphemic_structure" и создание нового столбца "cleaned_word"
df_merged['cleaned_word'] = df_merged['morphemic_structure'].apply(process_morphemic_structure)

# Вывод результата
print(df_merged)

# Функция для выделения основы и окончания
def end_forms(row):
    base_word = row['cleaned_word']
    word_form = row['form_lemma']
    base_length = len(base_word)
    suffix = word_form[base_length:]
    return suffix

# Создание нового столбца с окончаниями
df_merged['end'] = df_merged.apply(end_forms, axis=1)

# Вывод результата
print(df_merged)

# Сохранение результатов в CSV файл
df_merged.to_csv('end_forms.csv', index=False)

# Функция для обработки каждой строки в столбце (делим на морфемы основы косвенных форм)
def process_morphemic_structure(row):
    # Разделение строки по символу
    base_word = row.rsplit('/', 1)[0]
    return base_word

# Применение функции к столбцу "morphemic_structure" и создание нового столбца "base_word"
df_merged['base_word'] = df_merged['morphemic_structure'].apply(process_morphemic_structure)

# Вывод результата
print(df_merged)

# Делаем столбец с окончаниями
df_merged['end'] = '/' + df_merged['end'] + ':END'
print(df_merged)

# Соединяем два столбца в один, в котором представлено морфемное членение косвенных форм
df_merged['morphemic_structure'] = df_merged['base_word'] + df_merged['end']
df_merged.head()

# Переименование столбцов
df_merged = df_merged.rename(columns={'lemma': 'lemma_old'})
df_merged = df_merged.rename(columns={'form_lemma': 'lemma'})

# Отбор нужных столбцов
df_merged = df_merged[['lemma_old','lemma', 'morphemic_structure', 'pos']]

# Удаление строк, где значения в столбцах 'lemma_old' и 'lemma' одинаковые
df_merged = df_merged[df_merged['lemma_old'] != df_merged['lemma']]

# Вывод результата
df_merged.head()

# Отбор нужных столбцов
df_merged = df_merged[['lemma', 'morphemic_structure', 'pos']]

# Сохранение файла
df_merged.to_csv('tikhonov_forms.csv')