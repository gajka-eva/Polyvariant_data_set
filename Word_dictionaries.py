# -*- coding: utf-8 -*-
"""Word_dictionaries.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F-fvHfsTq5DtOrVqj0DkJW02hLTm9Gwn
"""

import pandas as pd

# Загрузка файлов
ke = pd.read_csv('/content/KE_data.csv')
ke = ke[['lemma', 'pos']]

ti = pd.read_csv('/content/tikhonov_data.csv')
ti = ti[['lemma', 'pos']]

it = pd.read_csv('/content/itkin_data.csv')
it = it[['lemma', 'pos']]

# Создание списков
ke_list = ke['lemma'].to_list()
ti_list = ti['lemma'].to_list()
it_list = it['lemma'].to_list()

# Соединение датасетов в один
df = pd.concat([ke, ti, it], ignore_index=True)

# Удаление дубликатов
df = df.drop_duplicates()

# Создание списка слов
list_words = df['lemma'].to_list()

# Создание по каждому списку слов отдельных датасетов списков слов, которых не хватает
result_ke = [word for word in list_words if word not in ke_list]
result_ti = [word for word in list_words if word not in ti_list]
result_it = [word for word in list_words if word not in it_list]

len(result_ke)

len(result_ti)

len(result_it)

# Преобразование в датасеты
ke_list_plus = pd.DataFrame(result_ke, columns=["lemma"])
ti_list_plus = pd.DataFrame(result_ti, columns=["lemma"])
it_list_plus = pd.DataFrame(result_it, columns=["lemma"])

# Выполнение соединения по столбцу 'lemma', создание датасетов со словами, которые надо разобрать
ke_plus = pd.merge(df, ke_list_plus, on='lemma', how='inner')
ke_plus = ke_plus.drop_duplicates()
ke_plus.head()

ti_plus = pd.merge(df, ti_list_plus, on='lemma', how='inner')
ti_plus = ti_plus.drop_duplicates()
ti_plus.head()

it_plus = pd.merge(df, it_list_plus, on='lemma', how='inner')
it_plus = it_plus.drop_duplicates()
it_plus.head()

# Сохранение датасетов
ke_plus.to_csv('КЕ_добавить.csv')
ti_plus.to_csv('Тихонов_добавить.csv')
it_plus.to_csv('Иткин_добавить.csv')