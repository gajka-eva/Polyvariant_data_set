# -*- coding: utf-8 -*-
"""Analysis_of_КЕ_dictionary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ittKMHvG8yezsqC51rW7myD_yHu7H13S
"""

# Загрузка необходимых библиотек
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

# Загрузка датасета
data = pd.read_csv('/content/morphodict_2023 - morphodict_2023 (1).csv')
data.head()

# Выбор нужных столбцов
data = data[['Lemma', 'Morph', 'Status', 'Place', 'POS']]
data.head()

# Объединение морфем для каждого слова c их статусом в одну запись
data['morphemic_structure'] = data['Morph'] + ':' + data['Status']
# Объединение столбцов с леммой и частью речи
data['lemma'] = data['Lemma'] + ':' + data['POS']

# Выбор необходимых столбцов
data = data[['lemma', 'morphemic_structure']]
# Проверка
data.head()

# Группировка данных по столбцу "Lemma" и объединение значений в столбце "morphemic_structure" через знак слеша
ke = data.groupby('lemma')['morphemic_structure'].apply('/'.join).reset_index()

# Проверка
ke.head()

# Возвращение столбца с частью речи
ke[['lemma', 'pos']] = ke['lemma'].str.split(':', expand=True)
# Проверка
ke.head(2)

# Добавление столбца с указанием источника
ke['author'] = 'КЕ'
# Проверка
ke.head(2)

# Добавление нулевых окончаний
ke.loc[(ke['pos'] == 'S') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'A') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'NUM') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'APRO') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'A,S') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'NUM,S') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'APRO,SPRO') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'
ke.loc[(ke['pos'] == 'ANUM,APRO,S') & (~ke['morphemic_structure'].str.endswith('END')), 'morphemic_structure'] += '/Ø:END'

# Проверка того, во всех ли случаях ть обозначается как END
ke.loc[(ke['lemma'].str.endswith('ть'))&(ke['pos'] == "V")&(~ke['morphemic_structure'].str.endswith('END'))]

# Замена ть:SUFF на ть:END
ke.loc[ke['pos'] == 'V','morphemic_structure'] = ke.loc[ke['pos'] == 'V','morphemic_structure'].str.replace('ть:SUFF', 'ть:END')

# Проверка
ke.loc[(ke['lemma'].str.endswith('ть'))&(ke['pos'] == "V")&(~ke['morphemic_structure'].str.endswith('END'))]

# Проверка данных
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('я'))]
# Ошибка связана с тем, что в первоначальном датасете во всех 803 словах пропущено окончание я

# Замена знака Ø на я в столбце morphemic_structure, если слово заканчивается на 'я'
ke['morphemic_structure'] = ke.apply(lambda row: row['morphemic_structure'].replace('Ø:END', 'я:END') if row['lemma'].endswith('я') else row['morphemic_structure'], axis=1)

# Проверка
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('я'))]

# Проверка данных
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('а'))]
# Добавление нулевых окончаний произошло по двум причинам:
# либо из-за того, что отсутствовало окончание в первоначальной записи
# либо из-за того, что окончание а было обозначено в первоначальной записи как суффикс

# Функция для замены Ø:END на а:END
def replace_ending(row):
    if row['lemma'].endswith('а') and row['morphemic_structure'].endswith('Ø:END') and 'а:SUFF' not in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', 'а:END')
    else:
        return row['morphemic_structure']

# Применение функции к DataFrame
ke['morphemic_structure'] = ke.apply(replace_ending, axis=1)

# Функция для удаления Ø:END там, где быть не должно
def remove_ending(row):
    if row['lemma'].endswith('а') and 'а:SUFF/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', '')
    else:
        return row['morphemic_structure']

# Применение функции к DataFrame
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)

# Проверка
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('а'))]

# Добавление окончания а
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('а')), 'morphemic_structure'] = 'ко:PREF/ордин:ROOT/а:SUFF/т:SUFF/а:END'

# Проверка
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('а'))]

# Проверка данных
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('о'))]
# Добавление нулевых окончаний произошло по трем причинам:
# либо из-за того, что окончание о было обозначено в первоначальной записи как суффикс,
# либо из-за того, что ошибочно определена часть речи в первоначальном датасете,
# либо из-за того, что существительное неизменяемое и не должно иметь нулевого окончания

# Функция для удаления Ø:END
def remove_ending(row):
    if row['lemma'].endswith('о') and 'о:SUFF/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', '')
    else:
        return row['morphemic_structure']

# Применение функции к DataFrame
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)


# Функция для удаления Ø:END
def remove_ending(row):
    if row['lemma'].endswith('о') and 'о:ROOT/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', '')
    else:
        return row['morphemic_structure']

# Применение функции к DataFrame
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)


# Функция для замены Ø:END на о:END
def remove_ending(row):
    if row['lemma'].endswith('о') and 'ишк:SUFF/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', 'о:END')
    else:
        return row['morphemic_structure']

# Применение функции
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)

# Проверка
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('о'))]

# Проверка данных
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('е'))]
# Добавление нулевых окончаний произошло по четырем причинам:
# либо из-за того, что окончание е было обозначено в первоначальной записи как суффикс,
# либо из-за того, что окончание отсутствовало в первоначальное записи,
# либо из-за того, что ошибочно определена часть речи в первоначальном датасете,
# либо из-за того, что существительное неизменяемое и не должно иметь нулевого окончания

# Функция для удаления Ø:END
def remove_ending(row):
    if row['lemma'].endswith('е') and 'е:SUFF/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', '')
    else:
        return row['morphemic_structure']

# Применение функции
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)


# Функция для замены Ø:END на е:END
def remove_ending(row):
    if row['lemma'].endswith('е') and 'и:SUFF/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', 'е:END')
    else:
        return row['morphemic_structure']

# Применение функции
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)


# Функция для удаления Ø:END у неизменяемых слов
def remove_ending(row):
    if row['lemma'].endswith('е') and 'е:ROOT/Ø:END' in row['morphemic_structure']:
        return row['morphemic_structure'].replace('Ø:END', '')
    else:
        return row['morphemic_structure']

# Применение функции
ke['morphemic_structure'] = ke.apply(remove_ending, axis=1)

# Проверка
ke.loc[(ke['morphemic_structure'].str.endswith('Ø:END'))&(ke['lemma'].str.endswith('е'))]

"""Остальные опечатки удаляем вручную, используя анализ количества морфем в слове, а также количество корней, приставок, суффиксов и окончаний"""

# Функция для подсчета количества морфем
def count_slash(morphemic_structure):
    return morphemic_structure.count('/') + 1

# Применением функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "morphema_count"
ke['morphema_count'] = ke['morphemic_structure'].apply(count_slash)

# Проверка
ke.head()

# Статстика по количеству морфем в словах
ke['morphema_count'].value_counts()

# Вывод слов, в морфемной стуктуре которых 14 морфем
ke.query('morphema_count == 14')

# Вывод слов, в морфемной стуктуре которых 12 морфем
ke.query('morphema_count == 12')

# Вывод слов, в морфемной стуктуре которых 11 морфем
ke.query('morphema_count == 11')

# Вывод слов, в морфемной стуктуре которых 10 морфем
ke.query('morphema_count == 10')

# Функция для подсчета количества корней
def count_slash(morphemic_structure):
    return morphemic_structure.count('ROOT')

# Применение функци к столбцу "morphemic_structure" и добавление результатов в новый столбец "root_count"
ke['root_count'] = ke['morphemic_structure'].apply(count_slash)

ke.head()

# Вывод количества слов с разным количеством корней
ke['root_count'].value_counts()

# Проверка
ke.query('root_count == 0')

"""Большое количество морфем объясняется тем, что при соединении морфем в единую морфемную структуру произошло соединение морфемных структур одинаковых слов. Такие неточности мы убираем вручную."""

# Сохранение датасета для работы с ним вручную
ke.to_csv('morphemic_structure_KE.csv')

# Загружаем обработанный датасет
ke = pd.read_csv('/content/morphemic_structure_KE.csv')

# Повторно считаем количество морфем в каждом слове
# Функция для подсчета количества морфем
def count_slash(morphemic_structure):
    return morphemic_structure.count('/') + 1

# Применение функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "morphema_count"
ke['morphema_count'] = ke['morphemic_structure'].apply(count_slash)

# Проверка
ke.head()

# Вывод количества слов с разным количеством морфем
ke['morphema_count'].value_counts()

"""Теперь самое большое количество морфем имеют сложные слова."""

# Проверка
ke.query('morphema_count == 11')

# Процентное соотношение
percentages = ke['morphema_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
#fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, hole=.3, hoverinfo='label+percent')])
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])

# Заголовок
fig.update_layout(title_text="Распределение количества морфем в процентном соотношении")

# Отображение диаграммы
fig.show()

# Функция для подсчета количества приставок
def count_slash(morphemic_structure):
    return morphemic_structure.count('PREF')

# Применение функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "pref_count"
ke['pref_count'] = ke['morphemic_structure'].apply(count_slash)

ke.head()

# Вывод количества слов с разным количеством приставок
ke['pref_count'].value_counts()

# Проверка
ke.query('pref_count == 3')

# Процентное соотношение
percentages = ke['pref_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])
# Заголовок
fig.update_layout(title_text="Распределение количества приставок в процентном соотношении")

# Отображение диаграммы
fig.show()

# Функция для подсчета количества корней
def count_slash(morphemic_structure):
    return morphemic_structure.count('ROOT')

# Применение функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "root_count"
ke['root_count'] = ke['morphemic_structure'].apply(count_slash)

ke.head()

# Вывод количества слов с разным количеством корней
ke['root_count'].value_counts()

# Проверка
ke.query('root_count == 4')

# Процентное соотношение
percentages = ke['root_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])
# Заголовок
fig.update_layout(title_text="Распределение количества приставок в процентном соотношении")

# Отображение диаграммы
fig.show()

# Функция для подсчета количества суффиксов
def count_slash(morphemic_structure):
    return morphemic_structure.count('SUFF')

# Применение функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "suff_count"
ke['suff_count'] = ke['morphemic_structure'].apply(count_slash)

ke.head()

# Вывод количества слов с разным количеством суффиксов
ke['suff_count'].value_counts()

# Проверка
ke.query('suff_count == 7')

# Процентное соотношение
percentages = ke['suff_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])
# Заголовок
fig.update_layout(title_text="Распределение количества приставок в процентном соотношении")

# Отображение диаграммы
fig.show()

# Функция для подсчета количества окончаний
def count_slash(morphemic_structure):
    return morphemic_structure.count('END')

# Применение функции к столбцу "morphemic_structure" и добавление результатов в новый столбец "end_count"
ke['end_count'] = ke['morphemic_structure'].apply(count_slash)

# Проверка
ke.head()

# Вывод количества слов с разным количеством окончаний
ke['end_count'].value_counts()

# Проверка
ke.query('end_count == 2')

# Процентное соотношение
percentages = ke['end_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])
# Заголовок
#fig.update_layout(title_text="Распределение количества приставок в процентном соотношении")

# Отображение диаграммы
fig.show()

# Функция для подсчета количества интерфиксов
def count_slash(morphemic_structure):
    return morphemic_structure.count('LINK')

# Применение функцию к столбцу "morphemic_structure" и добавление результат в новый столбец "link_count"
ke['link_count'] = ke['morphemic_structure'].apply(count_slash)

# Проверка
ke.head()

# Вывод количества слов с разным количеством интерфиксов
ke['link_count'].value_counts()

# Проверка
ke.query('link_count == 2').head(50)

# Процентное соотношение
percentages = ke['link_count'].value_counts(normalize=True) * 100

# Круговая диаграмма
fig = go.Figure(data=[go.Pie(labels=percentages.index, values=percentages.values, customdata=percentages.values,
                             hovertemplate='%{label}: %{customdata:.1f}%', textinfo='label+percent', hole=0.3)])
# Заголовок
fig.update_layout(title_text="Распределение количества приставок в процентном соотношении")

# Отображение диаграммы
fig.show()

ke.to_csv('morphemic_structure_KE_good.csv')

# Уникальные морфемные структуры
unique_morphemic_structures = set()

for structure in data['morphemic_structure']:
    unique_morphemic_structures.update(structure.split('/'))

print("Уникальные морфемные структуры:")
print(unique_morphemic_structures)

# Фильтрация только непустых строк
unique_morphemic_structures = [structure for structure in unique_morphemic_structures if structure]

# Отфильтрованный список
print(unique_morphemic_structures)

vocab_size = len(unique_morphemic_structures)
print("Размер словаря:", vocab_size)

# Создание датасета с одним столбцом
df = pd.DataFrame({'morphemic_structure': unique_morphemic_structures})

# Вывод датасета
df.head()

# Разделение столбца на два по двоеточию
df[['morphema', 'status']] = df['morphemic_structure'].str.split(':', expand=True)

# Вывод датасетв с разделенными столбцами
df.head()

# Количество уникальных значений и их частоты в столбце 'status'
status_counts = df['status'].value_counts()

# Создание датасета для построения круговой диаграммы
status_df = pd.DataFrame({'status': status_counts.index, 'count': status_counts.values})

# Круговая диаграмма
fig = px.pie(status_df, values='count', names='status', title='Распределение типов морфем')
fig.show()

# Функция для фильтрации статусов
def filter_statuses(statuses):
    filtered_statuses = [status.split(':')[1].strip() for status in statuses.split('/') if len(status.split(':')) > 1 and status.split(':')[1].strip() in {'ROOT', 'SUFF', 'END', 'PREF', 'LINK'}]
    return filtered_statuses

# Применение фильтрации к каждой морфемной структуре
data['morpheme_statuses'] = data['morphemic_structure'].apply(filter_statuses)
data.head(50)

data['morpheme_statuses'].value_counts()